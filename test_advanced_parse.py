#!/usr/bin/env python3
"""–§–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç - –ø–∞—Ä—Å–∏–Ω–≥ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ JSON"""

import asyncio
import json
import sys
from pathlib import Path
from datetime import datetime

sys.path.insert(0, str(Path(__file__).parent / 'src'))

from deepscraper.runner.browser import BrowserRunner

async def final_parsing_test():
    """–§–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –¥–∞–Ω–Ω—ã—Ö"""
    print("üöÄ –§–ò–ù–ê–õ–¨–ù–´–ô –¢–ï–°–¢: –ü–∞—Ä—Å–∏–Ω–≥ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")

    runner = BrowserRunner()
    results = []

    try:
        async with runner.context() as page:
            await runner.navigate(page, "https://books.toscrape.com")
            await page.wait_for_load_state("networkidle")

            print("üìä –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –∫–Ω–∏–≥–∞—Ö...")

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –æ –∫–Ω–∏–≥–∞—Ö
            books_data = await page.evaluate("""
                () => {
                    const books = [];
                    const articles = document.querySelectorAll('article.product_pod');

                    articles.forEach(article => {
                        const title = article.querySelector('h3 a')?.title || article.querySelector('h3 a')?.textContent.trim();
                        const price = article.querySelector('.price_color')?.textContent.trim();
                        const availability = article.querySelector('.instock.availability')?.textContent.trim().replace(/\s+/g, ' ');
                        const link = article.querySelector('h3 a')?.href;

                        if (title && price) {
                            books.push({
                                title: title,
                                price: price,
                                availability: availability || 'In stock',
                                link: link ? new URL(link, window.location.href).href : ''
                            });
                        }
                    });

                    return books;
                }
            """)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            results = books_data[:10]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 10 –∫–Ω–∏–≥

            print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(results)} –∫–Ω–∏–≥:")
            for i, book in enumerate(results):
                print(f"   {i+1}. {book['title']} - {book['price']}")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON
            output_data = {
                "source": "https://books.toscrape.com",
                "scraped_at": datetime.now().isoformat(),
                "books_count": len(results),
                "books": results
            }

            with open("parsing_results.json", "w", encoding="utf-8") as f:
                json.dump(output_data, f, indent=2, ensure_ascii=False)

            print("üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ parsing_results.json")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

    print("üéâ –§–ò–ù–ê–õ–¨–ù–´–ô –¢–ï–°–¢ –ó–ê–í–ï–†–®–ï–ù!")
    return results

if __name__ == "__main__":
    books = asyncio.run(final_parsing_test())
    print(f"\nüìà –ò–¢–û–ì: –£—Å–ø–µ—à–Ω–æ —Å–æ–±—Ä–∞–Ω–æ {len(books)} –∫–Ω–∏–≥")